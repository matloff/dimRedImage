{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tdasweep_histology.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5o60e0gsn8n"
      },
      "source": [
        "# Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_-M3uj6ybQQ"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import keras \n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import Conv2D, Dense, MaxPool2D, Dropout, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import statistics"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkSGDWvhxAeD"
      },
      "source": [
        "# Experiments: Histology-MNIST (28x28)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05UJZoQh2kcI"
      },
      "source": [
        "## Experiment 1: PCA + AlexNet & PCA + LeNet 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1roivb8zEVN"
      },
      "source": [
        "# read dataset\n",
        "histology_dataset = pd.read_csv(\"./hmnist_28_28_L.csv\")\n",
        "\n",
        "# process and formatting\n",
        "X = histology_dataset.iloc[:,0:784]\n",
        "y = histology_dataset.loc[:,'label']\n",
        "X_tensor = X.values.reshape(5000, 28, 28, 1)\n",
        "\n",
        "# train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y, test_size=0.2, shuffle=True, random_state=10)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, shuffle=True, random_state=11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFHUxegX4zqm"
      },
      "source": [
        "### PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGO2HSup1j_a"
      },
      "source": [
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "pca = PCA(n_components=332)\n",
        "start_time = time.time()\n",
        "principalComponents = pca.fit_transform(X_scaled)\n",
        "print(\"train time in seconds:\", time.time() - start_time)\n",
        "principalDf = pd.DataFrame(data = principalComponents)\n",
        "\n",
        "# train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(principalDf, y, test_size=0.2, shuffle=True, random_state=10)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, shuffle=True, random_state=11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHrQxQWv46fP"
      },
      "source": [
        "### AlexNet fully connected layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za4MCSZnEqpm"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIAU4AHT-Ex2"
      },
      "source": [
        "accuracy_pca_alex = []\n",
        "\n",
        "for i in range(20):\n",
        "  print(i)\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Dense(4096, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(4096, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    adam = Adam(lr=5e-4)\n",
        "    earlyStopping = EarlyStopping(monitor='val_accuracy', patience=25, verbose=0, mode='min')\n",
        "    mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_accuracy', mode='min')\n",
        "    model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val), callbacks=[earlyStopping, mcp_save])\n",
        "    print(\"train time in seconds:\", time.time() - start_time)\n",
        "    prediction = model.predict_classes(X_test)\n",
        "    report = classification_report(y_test, prediction, output_dict=True)\n",
        "    accuracy_pca_alex.append(report['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7NvTnoj5BAM"
      },
      "source": [
        "### Le-Net 5 fully connected layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFHaHGMwW-EE"
      },
      "source": [
        "accuracy_pca_lenet = []\n",
        "\n",
        "for i in range(20):\n",
        "  print(i)\n",
        "  model = keras.models.Sequential([\n",
        "      keras.layers.Dense(332, activation='tanh'), #C5\n",
        "      keras.layers.Dense(84, activation='tanh'), #F6\n",
        "      keras.layers.Dense(10, activation='softmax') #Output layer\n",
        "  ])\n",
        "  adam = Adam(lr=5e-4)\n",
        "  earlyStopping = EarlyStopping(monitor='val_accuracy', patience=20, verbose=0, mode='min')\n",
        "  mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_accuracy', mode='min')\n",
        "  model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n",
        "  start_time = time.time()\n",
        "\n",
        "  model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val), callbacks=[earlyStopping, mcp_save])\n",
        "  print(\"train time in seconds:\", time.time() - start_time)\n",
        "  prediction = model.predict_classes(X_test)\n",
        "  report = classification_report(y_test, prediction, output_dict=True)\n",
        "  accuracy_pca_lenet.append(report['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlMon4C75WZo"
      },
      "source": [
        "## Experiment 2: Full AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkHkHMPy5iEz"
      },
      "source": [
        "# read dataset\n",
        "histology_dataset = pd.read_csv(\"./hmnist_28_28_L.csv\")\n",
        "\n",
        "# process and formatting\n",
        "X = histology_dataset.iloc[:,0:784]\n",
        "y = histology_dataset.loc[:,'label']\n",
        "X_tensor = X.values.reshape(5000, 28, 28, 1)\n",
        "\n",
        "# train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y, test_size=0.2, shuffle=True, random_state=10)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, shuffle=True, random_state=11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dfhyywq62pnc"
      },
      "source": [
        "### Train AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXL7MMwdrWb-"
      },
      "source": [
        "accuracy_alexnet = []\n",
        "\n",
        "for i in range(20):\n",
        "  print(i)\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    model = keras.models.Sequential([\n",
        "      keras.layers.UpSampling2D(size=(8,8)),\n",
        "      keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(28,28,1)),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "      keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "      keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dense(4096, activation='relu'),\n",
        "      keras.layers.Dropout(0.5),\n",
        "      keras.layers.Dense(4096, activation='relu'),\n",
        "      keras.layers.Dropout(0.5),\n",
        "      keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "    adam = Adam(lr=5e-4)\n",
        "    earlyStopping = EarlyStopping(monitor='val_accuracy', patience=20, verbose=0, mode='min')\n",
        "    mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_accuracy', mode='min')\n",
        "    model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n",
        "    X_train = tf.cast(X_train, tf.float32)\n",
        "    X_test = tf.cast(X_test, tf.float32)\n",
        "    start_time = time.time()\n",
        "    history = model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val), callbacks=[earlyStopping, mcp_save])\n",
        "    print(\"train time in seconds:\", time.time() - start_time)\n",
        "    prediction = model.predict_classes(X_test)\n",
        "    report = classification_report(y_test, prediction, output_dict=True)\n",
        "    accuracy_alexnet.append(report['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaAs2pcQ5qJ6"
      },
      "source": [
        "## Experiment 3: Full Le-Net 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9axoEvwB6Ac1"
      },
      "source": [
        "# read dataset\n",
        "histology_dataset = pd.read_csv(\"./hmnist_28_28_L.csv\")\n",
        "\n",
        "# process and formatting\n",
        "X = histology_dataset.iloc[:,0:784]\n",
        "y = histology_dataset.loc[:,'label']\n",
        "X_tensor = X.values.reshape(5000, 28, 28, 1)\n",
        "\n",
        "# train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y, test_size=0.2, shuffle=True, random_state=10)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, shuffle=True, random_state=11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-dx1BMt6BcZ"
      },
      "source": [
        "### Train Le-Net 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knl16r1m5-Ao"
      },
      "source": [
        "# read dataset\n",
        "histology_dataset = pd.read_csv(\"./hmnist_28_28_L.csv\")\n",
        "\n",
        "# process and formatting\n",
        "X = histology_dataset.iloc[:,0:784]\n",
        "y = histology_dataset.loc[:,'label']\n",
        "X_tensor = X.values.reshape(5000, 28, 28, 1)\n",
        "\n",
        "# train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y, test_size=0.2, shuffle=True, random_state=10)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, shuffle=True, random_state=11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUobBArnJSD9"
      },
      "source": [
        "accuracy_lenet = []\n",
        "\n",
        "for i in range(20):\n",
        "  print(i)\n",
        "  model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(6, kernel_size=5, strides=1,  activation='tanh', input_shape=(28,28,1), padding='same'), #C1\n",
        "    keras.layers.AveragePooling2D(), #S2\n",
        "    keras.layers.Conv2D(16, kernel_size=5, strides=1, activation='tanh', padding='valid'), #C3\n",
        "    keras.layers.AveragePooling2D(), #S4\n",
        "    keras.layers.Flatten(), #Flatten\n",
        "    keras.layers.Dense(120, activation='tanh'), #C5\n",
        "    keras.layers.Dense(84, activation='tanh'), #F6\n",
        "    keras.layers.Dense(10, activation='softmax') #Output layer\n",
        "])\n",
        "  adam = Adam(lr=5e-4)\n",
        "  earlyStopping = EarlyStopping(monitor='val_accuracy', patience=20, verbose=0, mode='min')\n",
        "  mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_accuracy', mode='min')\n",
        "  model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n",
        "  start_time = time.time()\n",
        "  history = model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val), callbacks=[earlyStopping, mcp_save])\n",
        "  print(\"train time in seconds:\", time.time() - start_time)\n",
        "  prediction = model.predict_classes(X_test)\n",
        "  report = classification_report(y_test, prediction, output_dict=True)\n",
        "  accuracy_lenet.append(report['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YNB5Xl-6Lpp"
      },
      "source": [
        "## Experiment 4: TDAsweep + AlexNet & TDAsweep + Le-Net 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HRjvUf96mTa"
      },
      "source": [
        "### Load already processed dataset (TDAsweep)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BXj40UYAhF_"
      },
      "source": [
        "tdasweep_train = pd.read_csv(\"../prerun_tdasweep/histology_tdasweep\")\n",
        "tdasweep_test = pd.read_csv(\"../prerun_tdasweep/histology_tdasweep_test\")\n",
        "\n",
        "tdasweep_train_X = tdasweep_train.iloc[:,0:168]\n",
        "tdasweep_train_y = tdasweep_train.loc[:,'labels']\n",
        "\n",
        "tdasweep_test_X = tdasweep_test.iloc[:,0:168]\n",
        "tdasweep_test_y = tdasweep_test.loc[:,'labels']\n",
        "\n",
        "# train test split\n",
        "tdasweep_train_X, tdasweep_val_X, tdasweep_train_y, tdasweep_val_y = train_test_split(tdasweep_train_X, tdasweep_train_y, test_size=0.1, shuffle=True, random_state=11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eksLG7lY6aWN"
      },
      "source": [
        "### TDAsweep + AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2G8705dIxg-"
      },
      "source": [
        "accuracy_tdasweep_alex = []\n",
        "\n",
        "for i in range(20):\n",
        "  print(i)\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Dense(4096, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(4096, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    adam = Adam(lr=5e-4)\n",
        "    earlyStopping = EarlyStopping(monitor='val_accuracy', patience=25, verbose=0, mode='min')\n",
        "    mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_accuracy', mode='min')\n",
        "    model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n",
        "    start_time = time.time()\n",
        "    model.fit(tdasweep_train_X, tdasweep_train_y, epochs=50, validation_data=(tdasweep_val_X, tdasweep_val_y), callbacks=[earlyStopping, mcp_save])\n",
        "    print(\"train time in seconds:\", time.time() - start_time)\n",
        "    prediction = model.predict_classes(tdasweep_test_X)\n",
        "    report = classification_report(tdasweep_test_y, prediction, output_dict=True)\n",
        "    accuracy_tdasweep_alex.append(report['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd3zdFX36cME"
      },
      "source": [
        "### TDAsweep + LeNet 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nIfvAfWMdjC"
      },
      "source": [
        "accuracy_tdasweep_lenet = []\n",
        "\n",
        "for i in range(20):\n",
        "  print(i)\n",
        "  model = keras.models.Sequential([\n",
        "      keras.layers.Dense(332, activation='tanh'), #C5\n",
        "      keras.layers.Dense(84, activation='tanh'), #F6\n",
        "      keras.layers.Dense(10, activation='softmax') #Output layer\n",
        "  ])\n",
        "  adam = Adam(lr=5e-4)\n",
        "  earlyStopping = EarlyStopping(monitor='val_accuracy', patience=25, verbose=0, mode='min')\n",
        "  mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_accuracy', mode='min')\n",
        "  model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n",
        "  start_time = time.time()\n",
        "  model.fit(tdasweep_train_X, tdasweep_train_y, epochs=50, validation_data=(tdasweep_val_X, tdasweep_val_y), callbacks=[earlyStopping, mcp_save])\n",
        "  print(\"train time in seconds:\", time.time() - start_time)\n",
        "  prediction = model.predict_classes(tdasweep_test_X)\n",
        "  report = classification_report(tdasweep_test_y, prediction, output_dict=True)\n",
        "  accuracy_tdasweep_lenet.append(report['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUPJsBVA8rRp"
      },
      "source": [
        "## Overall comparison and evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbLxpTB52vee"
      },
      "source": [
        "### Basic stats for accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JyUw-G39Hqw"
      },
      "source": [
        "import statistics \n",
        "pd.DataFrame(accuracy_alexnet).describe()\n",
        "pd.DataFrame(accuracy_lenet).describe()\n",
        "pd.DataFrame(accuracy_pca_alex).describe()\n",
        "pd.DataFrame(accuracy_pca_lenet).describe()\n",
        "pd.DataFrame(accuracy_tdasweep_alex).describe()\n",
        "pd.DataFrame(accuracy_tdasweep_lenet).describe()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WdykzcG9XQK"
      },
      "source": [
        "### Box-plot accuracy visualizations (over 20 runs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgC6vL-G9cgm"
      },
      "source": [
        "#### TDAsweep vs AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xUGi63V292r"
      },
      "source": [
        "accuracies = pd.DataFrame(np.vstack([np.asarray(accuracy_alexnet), np.asarray(accuracy_tdasweep_alex)]))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.boxplot(accuracies)\n",
        "plt.xticks([1,2], ('AlexNet', 'TDAsweep + AlexNet (FC)'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcoMLTnp9i0F"
      },
      "source": [
        "#### TDAsweep vs LeNet 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Raua4SIG-BR5"
      },
      "source": [
        "accuracies = pd.DataFrame(np.vstack([np.asarray(accuracy_lenet), np.asarray(accuracy_tdasweep_lenet)]))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.boxplot(accuracies)\n",
        "plt.xticks([1,2], ('Le-Net 5', 'TDAsweep + Le-Net 5 (FC)'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg9G6OHh9i6V"
      },
      "source": [
        "#### (Le-Net 5 fully connected) TDAsweep vs PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czZrLL-g-Bi_"
      },
      "source": [
        "accuracies = pd.DataFrame(np.vstack([np.asarray(accuracy_pca_lenet), np.asarray(accuracy_tdasweep_lenet)]))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.boxplot(accuracies)\n",
        "plt.xticks([1,2], ('PCA + Le-Net 5 (FC)', 'TDAsweep + Le-Net 5 (FC)'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inQ0aHHe9ueJ"
      },
      "source": [
        "#### (Le-Net 5 fully connected) TDAsweep vs PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrqKbKIY-B1O"
      },
      "source": [
        "accuracies = pd.DataFrame(np.vstack([np.asarray(accuracy_pca_alex), np.asarray(accuracy_tdasweep_alex)]))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.boxplot(accuracies)\n",
        "plt.xticks([1,2], ('PCA + AlexNet (FC)', 'TDAsweep + AlexNet (FC)'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8L_LPaxV3qoJ"
      },
      "source": [
        "# Other Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-HyQSu4_QbT"
      },
      "source": [
        "## OctMNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fimXdjPnNNGM"
      },
      "source": [
        "tdasweep_train = pd.read_csv(\"../prerun_tdasweep/octmnist_tdasweep_train\")\n",
        "tdasweep_test = pd.read_csv(\"../prerun_tdasweep/octmnist_tdasweep_test\")\n",
        "\n",
        "tdasweep_train_X = tdasweep_train.iloc[:,0:332]\n",
        "tdasweep_train_y = tdasweep_train.loc[:,'labels']\n",
        "\n",
        "tdasweep_test_X = tdasweep_test.iloc[:,0:332]\n",
        "tdasweep_test_y = tdasweep_test.loc[:,'labels']\n",
        "\n",
        "# train test split\n",
        "tdasweep_train_X, tdasweep_val_X, tdasweep_train_y, tdasweep_val_y = train_test_split(tdasweep_train_X, tdasweep_train_y, test_size=0.1, shuffle=True, random_state=11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZVI-Yzs_WPC"
      },
      "source": [
        "### TDAsweep + AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc0xfLOZNrw5"
      },
      "source": [
        "accuracy_tdasweep = []\n",
        "\n",
        "for i in range(20):\n",
        "  print(i)\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Dense(4096, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(4096, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    adam = Adam(lr=5e-4)\n",
        "    earlyStopping = EarlyStopping(monitor='val_accuracy', patience=25, verbose=0, mode='min')\n",
        "    mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_accuracy', mode='min')\n",
        "    model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n",
        "    start_time = time.time()\n",
        "    model.fit(tdasweep_train_X, tdasweep_train_y, epochs=50, validation_data=(tdasweep_val_X, tdasweep_val_y), callbacks=[earlyStopping, mcp_save])\n",
        "    print(\"train time in seconds:\", time.time() - start_time)\n",
        "    prediction = model.predict_classes(tdasweep_test_X)\n",
        "    report = classification_report(tdasweep_test_y, prediction, output_dict=True)\n",
        "    accuracy_tdasweep.append(report['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22laEGoA_aWe"
      },
      "source": [
        "## PneumoniaMNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVVYEI10qHoP"
      },
      "source": [
        "X_train = pd.read_csv(\"./pneumoniamnist_train_X.csv\")\n",
        "X_test = pd.read_csv(\"./pneumoniamnist_test_X.csv\")\n",
        "y_train = pd.read_csv(\"./pneumoniamnist_train_y.csv\")\n",
        "y_test = pd.read_csv(\"./pneumoniamnist_test_y.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPVzswimqHoP"
      },
      "source": [
        "X_train = X_train.iloc[:, 1:785]\n",
        "X_test = X_test.iloc[:, 1:785]\n",
        "y_train = y_train.iloc[:,1]\n",
        "y_test = y_test.iloc[:,1]\n",
        "\n",
        "X_train = X_train.values.reshape(4708, 28, 28, 1)\n",
        "X_test = X_test.values.reshape(624, 28, 28, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG060_Om_3b1"
      },
      "source": [
        "### Full AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIziksmCqHoQ"
      },
      "source": [
        "accuracy_alexnet = []\n",
        "\n",
        "for i in range(20):\n",
        "  print(i)\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    model = keras.models.Sequential([\n",
        "      keras.layers.UpSampling2D(size=(8,8)),\n",
        "      keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(28,28,1)),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "      keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "      keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dense(4096, activation='relu'),\n",
        "      keras.layers.Dropout(0.5),\n",
        "      keras.layers.Dense(4096, activation='relu'),\n",
        "      keras.layers.Dropout(0.5),\n",
        "      keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "    adam = Adam(lr=5e-4)\n",
        "    earlyStopping = EarlyStopping(monitor='val_accuracy', patience=20, verbose=0, mode='min')\n",
        "    mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_accuracy', mode='min')\n",
        "    model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n",
        "    X_train = tf.cast(X_train, tf.float32)\n",
        "    X_test = tf.cast(X_test, tf.float32)\n",
        "    start_time = time.time()\n",
        "    history = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), callbacks=[earlyStopping, mcp_save])\n",
        "    print(\"train time in seconds:\", time.time() - start_time)\n",
        "    prediction = model.predict_classes(X_test)\n",
        "    report = classification_report(y_test, prediction, output_dict=True)\n",
        "    accuracy_alexnet.append(report['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icd8LoSt_n1u"
      },
      "source": [
        "### TDAsweep + AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4M4deLkpUFR"
      },
      "source": [
        "tdasweep_train = pd.read_csv(\"../prerun_tdasweep/pneumoniamnist_tdasweep_train\")\n",
        "tdasweep_test = pd.read_csv(\"../prerun_tdasweep/pneumoniamnist_tdasweep_test\")\n",
        "\n",
        "tdasweep_train_X = tdasweep_train.iloc[:,0:332]\n",
        "tdasweep_train_y = tdasweep_train.loc[:,'labels']\n",
        "\n",
        "tdasweep_test_X = tdasweep_test.iloc[:,0:332]\n",
        "tdasweep_test_y = tdasweep_test.loc[:,'labels']\n",
        "\n",
        "# train test split\n",
        "tdasweep_train_X, tdasweep_val_X, tdasweep_train_y, tdasweep_val_y = train_test_split(tdasweep_train_X, tdasweep_train_y, test_size=0.1, shuffle=True, random_state=11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSVDE_ozpUFW"
      },
      "source": [
        "accuracy_tdasweep = []\n",
        "\n",
        "for i in range(20):\n",
        "  print(i)\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Dense(4096, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(4096, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    adam = Adam(lr=5e-4)\n",
        "    earlyStopping = EarlyStopping(monitor='val_accuracy', patience=25, verbose=0, mode='min')\n",
        "    mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_accuracy', mode='min')\n",
        "    model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n",
        "    start_time = time.time()\n",
        "    model.fit(tdasweep_train_X, tdasweep_train_y, epochs=50, validation_data=(tdasweep_val_X, tdasweep_val_y), callbacks=[earlyStopping, mcp_save])\n",
        "    print(\"train time in seconds:\", time.time() - start_time)\n",
        "    prediction = model.predict_classes(tdasweep_test_X)\n",
        "    report = classification_report(tdasweep_test_y, prediction, output_dict=True)\n",
        "    accuracy_tdasweep.append(report['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-RxVCZTwDyY"
      },
      "source": [
        "# Experiment: octMNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G96qo6bSwMW2"
      },
      "source": [
        "## Read datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9vMkbGQi_AA"
      },
      "source": [
        "X_train = pd.read_csv(\"./octmnist_train_X.csv\")\n",
        "X_test = pd.read_csv(\"./octmnist_test_X.csv\")\n",
        "y_train = pd.read_csv(\"./octmnist_train_y.csv\")\n",
        "y_test = pd.read_csv(\"./octmnist_test_y.csv\")\n",
        "\n",
        "# format\n",
        "X_train = X_train.iloc[:, 1:785]\n",
        "X_test = X_test.iloc[:, 1:785]\n",
        "y_train = y_train.iloc[:,1]\n",
        "y_test = y_test.iloc[:,1]\n",
        "X_train = X_train.values.reshape(97477, 28, 28, 1)\n",
        "X_test = X_test.values.reshape(1000, 28, 28, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHAaYbUEwX4Q"
      },
      "source": [
        "## Train AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXU17M5Xi_AC"
      },
      "source": [
        "accuracy_alexnet = []\n",
        "\n",
        "for i in range(20):\n",
        "  print(i)\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    model = keras.models.Sequential([\n",
        "      keras.layers.UpSampling2D(size=(8,8)),\n",
        "      keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(28,28,1)),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "      keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "      keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dense(4096, activation='relu'),\n",
        "      keras.layers.Dropout(0.5),\n",
        "      keras.layers.Dense(4096, activation='relu'),\n",
        "      keras.layers.Dropout(0.5),\n",
        "      keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "    adam = Adam(lr=5e-4)\n",
        "    earlyStopping = EarlyStopping(monitor='val_accuracy', patience=20, verbose=0, mode='min')\n",
        "    mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_accuracy', mode='min')\n",
        "    model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n",
        "    X_train = tf.cast(X_train, tf.float32)\n",
        "    X_test = tf.cast(X_test, tf.float32)\n",
        "    start_time = time.time()\n",
        "    history = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), callbacks=[earlyStopping, mcp_save])\n",
        "    print(\"train time in seconds:\", time.time() - start_time)\n",
        "    prediction = model.predict_classes(X_test)\n",
        "    report = classification_report(y_test, prediction, output_dict=True)\n",
        "    accuracy_alexnet.append(report['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}